
The following have been reloaded with a version change:
  1) GCCcore/9.3.0 => GCCcore/8.3.0
  2) binutils/2.34-GCCcore-9.3.0 => binutils/2.32-GCCcore-8.3.0
  3) zlib/1.2.11-GCCcore-9.3.0 => zlib/1.2.11-GCCcore-8.3.0


The following have been reloaded with a version change:
  1) GCCcore/8.3.0 => GCCcore/9.3.0
  2) binutils/2.32-GCCcore-8.3.0 => binutils/2.34-GCCcore-9.3.0
  3) zlib/1.2.11-GCCcore-8.3.0 => zlib/1.2.11-GCCcore-9.3.0

2021-02-02 16:34:33 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_vaswani_wmt_en_de_big', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../../data-bin/phrase4_0.5_tag_rare_GNOME', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.2, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=8192, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args=None, eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=10, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='../../../models/wmt19.de-en.joined-dict.ensemble//model1.pt', save_dir='../checkpoints/GNOME_p_9_r', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001)
2021-02-02 16:34:34 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types
2021-02-02 16:34:34 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types
2021-02-02 16:34:34 | INFO | fairseq.data.data_utils | loaded 151 examples from: ../../../data-bin/phrase4_0.5_tag_rare_GNOME/valid.de-en.de
2021-02-02 16:34:34 | INFO | fairseq.data.data_utils | loaded 151 examples from: ../../../data-bin/phrase4_0.5_tag_rare_GNOME/valid.de-en.en
2021-02-02 16:34:34 | INFO | fairseq.tasks.translation | ../../../data-bin/phrase4_0.5_tag_rare_GNOME valid de-en 151 examples
2021-02-02 16:34:40 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(42024, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(42024, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=42024, bias=False)
  )
)
2021-02-02 16:34:40 | INFO | fairseq_cli.train | model transformer_vaswani_wmt_en_de_big, criterion LabelSmoothedCrossEntropyCriterion
2021-02-02 16:34:40 | INFO | fairseq_cli.train | num. model params: 312778752 (num. trained: 312778752)
2021-02-02 16:34:50 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2021-02-02 16:34:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-02-02 16:34:50 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 32.000 GB ; name = GRID V100D-32Q                          
2021-02-02 16:34:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-02-02 16:34:50 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-02-02 16:34:50 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2021-02-02 16:34:59 | INFO | fairseq.trainer | loaded checkpoint ../../../models/wmt19.de-en.joined-dict.ensemble//model1.pt (epoch 16 @ 0 updates)
2021-02-02 16:34:59 | INFO | fairseq.trainer | loading train data for epoch 1
2021-02-02 16:34:59 | INFO | fairseq.data.data_utils | loaded 93982 examples from: ../../../data-bin/phrase4_0.5_tag_rare_GNOME/train.de-en.de
2021-02-02 16:34:59 | INFO | fairseq.data.data_utils | loaded 93982 examples from: ../../../data-bin/phrase4_0.5_tag_rare_GNOME/train.de-en.en
2021-02-02 16:34:59 | INFO | fairseq.tasks.translation | ../../../data-bin/phrase4_0.5_tag_rare_GNOME train de-en 93982 examples
2021-02-02 16:35:00 | INFO | fairseq_cli.train | begin training epoch 1
2021-02-02 16:35:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2021-02-02 16:35:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-02-02 16:35:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2021-02-02 16:35:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-02-02 16:35:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-02-02 16:35:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-02-02 16:35:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-02-02 16:35:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-02-02 16:35:21 | INFO | train_inner | epoch 001:    108 / 154 loss=4.083, nll_loss=2.414, ppl=5.33, wps=18305.1, ups=5.29, wpb=3462, bsz=598.1, num_updates=100, lr=1.25e-05, gnorm=16.298, loss_scale=1, train_wall=19, wall=30
2021-02-02 16:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:35:31 | INFO | fairseq.tasks.translation | example hypothesis: Select the category from the list. You can select as many categories as you like.
2021-02-02 16:35:31 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:35:32 | INFO | fairseq.tasks.translation | example hypothesis: POP downloads all messages to your local disk, but other types of connections often only download the headers, and everything else only if you really want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have selected to store.
2021-02-02 16:35:32 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:35:34 | INFO | fairseq.tasks.translation | example hypothesis: If a message uses the same header more than once, Evolution only evaluates its first occurrence, even if the message defines the header differently the second time. For example, if a message defines the UNKNOWNTOKENINHYP Resent-From: UNKNOWNTOKENINHYP header as UNKNOWNTOKENINHYP engineeringUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP and then again as UNKNOWNTOKENINHYP marketingUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP, Evolution filters as if the second value did not exist. Regular expressions are used to filter messages that define the same headers more than once.
2021-02-02 16:35:34 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:35:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.758 | nll_loss 2.06 | ppl 4.17 | bleu 33.4 | wps 955.2 | wpb 1401.3 | bsz 50.3 | num_updates 146
2021-02-02 16:35:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:35:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_best.pt (epoch 1 @ 146 updates, score 33.4) (writing took 18.57180199958384 seconds)
2021-02-02 16:35:53 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-02-02 16:35:53 | INFO | train | epoch 001 | loss 3.846 | nll_loss 2.155 | ppl 4.45 | wps 10060 | ups 2.86 | wpb 3517.1 | bsz 600.9 | num_updates 146 | lr 1.825e-05 | gnorm 12.263 | loss_scale 1 | train_wall 29 | wall 62
2021-02-02 16:35:53 | INFO | fairseq_cli.train | begin training epoch 1
2021-02-02 16:36:03 | INFO | train_inner | epoch 002:     54 / 154 loss=3.185, nll_loss=1.431, ppl=2.7, wps=8541.4, ups=2.36, wpb=3620.9, bsz=631.8, num_updates=200, lr=2.5e-05, gnorm=3.191, loss_scale=0, train_wall=19, wall=73
2021-02-02 16:36:22 | INFO | train_inner | epoch 002:    154 / 154 loss=3.023, nll_loss=1.256, ppl=2.39, wps=18547, ups=5.34, wpb=3473.6, bsz=587.2, num_updates=300, lr=3.75e-05, gnorm=2.81, loss_scale=0, train_wall=19, wall=92
2021-02-02 16:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:36:23 | INFO | fairseq.tasks.translation | example hypothesis: Select the category from the list. You can select as many categories as you like.
2021-02-02 16:36:23 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:36:24 | INFO | fairseq.tasks.translation | example hypothesis: POP downloads all messages to your local disk, but other types of connections often only download the headers, and everything else only if you really want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have selected to store.
2021-02-02 16:36:24 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:36:26 | INFO | fairseq.tasks.translation | example hypothesis: If a message uses the same header more than once, Evolution only evaluates its first occurrence, even if the message defines the header differently the second time. For example, if a message defines the Resent-From: UNKNOWNTOKENINHYP header as UNKNOWNTOKENINHYP engineeringUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP and then again as UNKNOWNTOKENINHYP marketingUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP, Evolution filters as if the second value did not exist. Regular expressions are used to filter messages that define the same headers more than once.
2021-02-02 16:36:26 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:36:26 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 3.654 | nll_loss 1.937 | ppl 3.83 | bleu 34.96 | wps 977.5 | wpb 1401.3 | bsz 50.3 | num_updates 300 | best_bleu 34.96
2021-02-02 16:36:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:36:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_best.pt (epoch 2 @ 300 updates, score 34.96) (writing took 25.424812691286206 seconds)
2021-02-02 16:36:51 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-02-02 16:36:51 | INFO | train | epoch 002 | loss 3.029 | nll_loss 1.26 | ppl 2.4 | wps 9281.9 | ups 2.64 | wpb 3520.5 | bsz 610.3 | num_updates 300 | lr 3.75e-05 | gnorm 2.854 | loss_scale 0 | train_wall 29 | wall 121
2021-02-02 16:36:51 | INFO | fairseq_cli.train | begin training epoch 2
2021-02-02 16:37:10 | INFO | train_inner | epoch 003:    100 / 154 loss=2.789, nll_loss=0.995, ppl=1.99, wps=7445.2, ups=2.07, wpb=3595.9, bsz=621.6, num_updates=400, lr=5e-05, gnorm=2.265, loss_scale=0, train_wall=19, wall=140
2021-02-02 16:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:37:21 | INFO | fairseq.tasks.translation | example hypothesis: Select the category from the list. You can select as many categories as you like.
2021-02-02 16:37:21 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:37:22 | INFO | fairseq.tasks.translation | example hypothesis: POP downloads all messages to your local disk, but other connections often only download the headers, and everything else until you really want to read the message. Before you go offline, Evolution downloads unread messages from the folders you have selected to store.
2021-02-02 16:37:22 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:37:24 | INFO | fairseq.tasks.translation | example hypothesis: If a message uses the same header more than once, Evolution only evaluates its first occurrence, even if the message redefines the header the second time. For example, if a message defines Resent-From: UNKNOWNTOKENINHYP as UNKNOWNTOKENINHYP engineeringUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP and then again as UNKNOWNTOKENINHYP marketingUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP, Evolution filters as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:37:24 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:37:24 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 3.66 | nll_loss 1.93 | ppl 3.81 | bleu 35.54 | wps 959.3 | wpb 1401.3 | bsz 50.3 | num_updates 454 | best_bleu 35.54
2021-02-02 16:37:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:37:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_best.pt (epoch 3 @ 454 updates, score 35.54) (writing took 22.25757190026343 seconds)
2021-02-02 16:37:46 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-02-02 16:37:46 | INFO | train | epoch 003 | loss 2.799 | nll_loss 1.007 | ppl 2.01 | wps 9809 | ups 2.79 | wpb 3520.5 | bsz 610.3 | num_updates 454 | lr 5.675e-05 | gnorm 2.264 | loss_scale 0 | train_wall 29 | wall 176
2021-02-02 16:37:46 | INFO | fairseq_cli.train | begin training epoch 3
2021-02-02 16:37:55 | INFO | train_inner | epoch 004:     46 / 154 loss=2.736, nll_loss=0.936, ppl=1.91, wps=7694.3, ups=2.22, wpb=3463.2, bsz=604.8, num_updates=500, lr=6.25e-05, gnorm=2.078, loss_scale=0, train_wall=19, wall=185
2021-02-02 16:38:14 | INFO | train_inner | epoch 004:    146 / 154 loss=2.638, nll_loss=0.828, ppl=1.78, wps=18825.4, ups=5.32, wpb=3540.3, bsz=612.3, num_updates=600, lr=7.5e-05, gnorm=1.868, loss_scale=0, train_wall=19, wall=204
2021-02-02 16:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:38:16 | INFO | fairseq.tasks.translation | example hypothesis: Select the category from the list. You can select as many categories as you like.
2021-02-02 16:38:16 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:38:17 | INFO | fairseq.tasks.translation | example hypothesis: POP downloads all messages to your local system, but other connections often only download the headers, and everything else until you really want to read the message. Before you go offline, Evolution downloads unread messages from the folders you have chosen to store.
2021-02-02 16:38:17 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:38:19 | INFO | fairseq.tasks.translation | example hypothesis: If a message uses the same header more than once, Evolution will only evaluate its first occurrence, even if the message redefines the header the second time. For example, if a message defines the Resent-From: UNKNOWNTOKENINHYP as UNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP and then again as UNKNOWNTOKENINHYP marketingUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP, Evolution will filter as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:38:19 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:38:19 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.701 | nll_loss 1.984 | ppl 3.95 | bleu 36.31 | wps 1014.6 | wpb 1401.3 | bsz 50.3 | num_updates 608 | best_bleu 36.31
2021-02-02 16:38:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:38:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_best.pt (epoch 4 @ 608 updates, score 36.31) (writing took 18.870202254503965 seconds)
2021-02-02 16:38:38 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-02-02 16:38:38 | INFO | train | epoch 004 | loss 2.637 | nll_loss 0.825 | ppl 1.77 | wps 10509.5 | ups 2.99 | wpb 3520.5 | bsz 610.3 | num_updates 608 | lr 7.6e-05 | gnorm 1.869 | loss_scale 0 | train_wall 29 | wall 228
2021-02-02 16:38:38 | INFO | fairseq_cli.train | begin training epoch 4
2021-02-02 16:38:55 | INFO | train_inner | epoch 005:     92 / 154 loss=2.535, nll_loss=0.708, ppl=1.63, wps=8349.6, ups=2.43, wpb=3441.6, bsz=590, num_updates=700, lr=8.75e-05, gnorm=1.572, loss_scale=0, train_wall=18, wall=245
2021-02-02 16:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:39:08 | INFO | fairseq.tasks.translation | example hypothesis: Select the category from the list. You can select as many categories as you like.
2021-02-02 16:39:08 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:39:09 | INFO | fairseq.tasks.translation | example hypothesis: POP downloads all messages to your local system, but other connections often only download the headers and everything else you really want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:39:09 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:39:10 | INFO | fairseq.tasks.translation | example hypothesis: If a message uses the same header more than once, Evolution will only evaluate its first occurrances, even if the message redefines the header the second time. For example, if a message defines the Resent-From: UNKNOWNTOKENINHYP as UNKNOWNTOKENINHYP engineeringUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP and then again as UNKNOWNTOKENINHYP marketingUNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP, Evolution will filter as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:39:10 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:39:10 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.776 | nll_loss 2.058 | ppl 4.17 | bleu 37.47 | wps 1045.3 | wpb 1401.3 | bsz 50.3 | num_updates 762 | best_bleu 37.47
2021-02-02 16:39:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:39:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_best.pt (epoch 5 @ 762 updates, score 37.47) (writing took 22.615495338104665 seconds)
2021-02-02 16:39:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-02-02 16:39:33 | INFO | train | epoch 005 | loss 2.512 | nll_loss 0.685 | ppl 1.61 | wps 9823.1 | ups 2.79 | wpb 3520.5 | bsz 610.3 | num_updates 762 | lr 9.525e-05 | gnorm 1.561 | loss_scale 0 | train_wall 29 | wall 283
2021-02-02 16:39:33 | INFO | fairseq_cli.train | begin training epoch 5
2021-02-02 16:39:40 | INFO | train_inner | epoch 006:     38 / 154 loss=2.462, nll_loss=0.63, ppl=1.55, wps=7916.5, ups=2.21, wpb=3578.3, bsz=607.7, num_updates=800, lr=0.0001, gnorm=1.553, loss_scale=0, train_wall=19, wall=290
2021-02-02 16:39:59 | INFO | train_inner | epoch 006:    138 / 154 loss=2.439, nll_loss=0.601, ppl=1.52, wps=18687.6, ups=5.34, wpb=3499.1, bsz=631, num_updates=900, lr=0.0001125, gnorm=1.461, loss_scale=0, train_wall=19, wall=309
2021-02-02 16:40:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:40:03 | INFO | fairseq.tasks.translation | example hypothesis: Select the category from the list. You can select as many categories as you like.
2021-02-02 16:40:03 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:40:04 | INFO | fairseq.tasks.translation | example hypothesis: POP downloads all messages to your local system, but other connections will often only download headers and everything else you need to read the message. Before you go offline, Evolution will download unread messages from the folders you have chosen to store.
2021-02-02 16:40:04 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:40:06 | INFO | fairseq.tasks.translation | example hypothesis: If a message uses the same header more than once, Evolution will only evaluate its first occurrances, even if the message redefines the header the second time. For example, if a message defines the Resent-From header as UNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP and then redefines it as UNKNOWNTOKENINHYP marketing UNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP, Evolution will filter as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:40:06 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:40:06 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.795 | nll_loss 2.055 | ppl 4.16 | bleu 37.51 | wps 1012.5 | wpb 1401.3 | bsz 50.3 | num_updates 916 | best_bleu 37.51
2021-02-02 16:40:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:40:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_best.pt (epoch 6 @ 916 updates, score 37.51) (writing took 23.11551800649613 seconds)
2021-02-02 16:40:29 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-02-02 16:40:29 | INFO | train | epoch 006 | loss 2.43 | nll_loss 0.592 | ppl 1.51 | wps 9682.6 | ups 2.75 | wpb 3520.5 | bsz 610.3 | num_updates 916 | lr 0.0001145 | gnorm 1.444 | loss_scale 0 | train_wall 29 | wall 339
2021-02-02 16:40:29 | INFO | fairseq_cli.train | begin training epoch 6
2021-02-02 16:40:45 | INFO | train_inner | epoch 007:     84 / 154 loss=2.37, nll_loss=0.525, ppl=1.44, wps=7591.9, ups=2.18, wpb=3481.4, bsz=606.4, num_updates=1000, lr=0.000125, gnorm=1.282, loss_scale=0, train_wall=19, wall=355
2021-02-02 16:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:40:59 | INFO | fairseq.tasks.translation | example hypothesis: Götz select the category from the list. You can select as many categories as you like.
2021-02-02 16:40:59 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:41:00 | INFO | fairseq.tasks.translation | example hypothesis: POP will download all messages to your local system, but other connections will only download headers and everything else until you really want to read the message. Before you go offline, Evolution will download the unread messages from the folders you have chosen to store.
2021-02-02 16:41:00 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:41:02 | INFO | fairseq.tasks.translation | example hypothesis: Götz If a message uses the same header more than once, Evolution will only evaluate its first occurrence, even if the message redefines the header as UNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP the second time, Evolution will filter as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:41:02 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:41:02 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.993 | nll_loss 2.321 | ppl 5 | bleu 35.39 | wps 1079.4 | wpb 1401.3 | bsz 50.3 | num_updates 1070 | best_bleu 37.51
2021-02-02 16:41:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:41:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_last.pt (epoch 7 @ 1070 updates, score 35.39) (writing took 9.147651224397123 seconds)
2021-02-02 16:41:11 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-02-02 16:41:11 | INFO | train | epoch 007 | loss 2.358 | nll_loss 0.511 | ppl 1.43 | wps 12961.3 | ups 3.68 | wpb 3520.5 | bsz 610.3 | num_updates 1070 | lr 0.00013375 | gnorm 1.222 | loss_scale 0 | train_wall 29 | wall 381
2021-02-02 16:41:11 | INFO | fairseq_cli.train | begin training epoch 7
2021-02-02 16:41:17 | INFO | train_inner | epoch 008:     30 / 154 loss=2.352, nll_loss=0.507, ppl=1.42, wps=11322.6, ups=3.15, wpb=3593.3, bsz=617, num_updates=1100, lr=0.0001375, gnorm=1.156, loss_scale=0, train_wall=19, wall=386
2021-02-02 16:41:35 | INFO | train_inner | epoch 008:    130 / 154 loss=2.322, nll_loss=0.47, ppl=1.38, wps=18611.7, ups=5.3, wpb=3512.5, bsz=610.6, num_updates=1200, lr=0.00015, gnorm=1.316, loss_scale=0, train_wall=19, wall=405
2021-02-02 16:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:41:41 | INFO | fairseq.tasks.translation | example hypothesis: Götz select the category from the list. You can select as many categories as you like.
2021-02-02 16:41:41 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:41:42 | INFO | fairseq.tasks.translation | example hypothesis: Götz UNKNOWNTOKENINHYP POP downloads all messages to your local system, but other connections often only download headers and don UNKNOWNTOKENINHYP t start until you really want to read the message. Before you go offline, Evolution will download the unread messages from the folders you have chosen to store.
2021-02-02 16:41:42 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:41:44 | INFO | fairseq.tasks.translation | example hypothesis: Götz Götz If a message uses the same header more than once, Evolution will only evaluate its first occurrence, even if the message redefines the header as UNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP the second time, Evolution will filter as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:41:44 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:41:44 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.044 | nll_loss 2.374 | ppl 5.18 | bleu 35.05 | wps 987.1 | wpb 1401.3 | bsz 50.3 | num_updates 1224 | best_bleu 37.51
2021-02-02 16:41:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:41:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_last.pt (epoch 8 @ 1224 updates, score 35.05) (writing took 8.147160611115396 seconds)
2021-02-02 16:41:52 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-02-02 16:41:52 | INFO | train | epoch 008 | loss 2.323 | nll_loss 0.472 | ppl 1.39 | wps 13165.5 | ups 3.74 | wpb 3520.5 | bsz 610.3 | num_updates 1224 | lr 0.000153 | gnorm 1.23 | loss_scale 0 | train_wall 29 | wall 422
2021-02-02 16:41:52 | INFO | fairseq_cli.train | begin training epoch 8
2021-02-02 16:42:07 | INFO | train_inner | epoch 009:     76 / 154 loss=2.281, nll_loss=0.425, ppl=1.34, wps=11374, ups=3.21, wpb=3543.3, bsz=609.7, num_updates=1300, lr=0.0001625, gnorm=1.103, loss_scale=0, train_wall=19, wall=436
2021-02-02 16:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:42:22 | INFO | fairseq.tasks.translation | example hypothesis: Götz select the category from the list. You can select as many categories as you like.
2021-02-02 16:42:22 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:42:23 | INFO | fairseq.tasks.translation | example hypothesis: Götz will download all the unread messages to your local system, but other connections will only download the headers, and everything else until you really want to read the message. Before you go offline, Evolution will download the unread messages from the folders you have chosen to store.
2021-02-02 16:42:23 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:42:25 | INFO | fairseq.tasks.translation | example hypothesis: Götz If a message uses the same header more than once, Evolution will only evaluate its first occurrence, even if the message redefines the header the second time. For example, if a message defines Resent-From as UNKNOWNTOKENINHYP example.com and then again as UNKNOWNTOKENINHYP marketing @ example.com, Evolution filters as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:42:25 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:42:25 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.24 | nll_loss 2.6 | ppl 6.06 | bleu 36.13 | wps 988.3 | wpb 1401.3 | bsz 50.3 | num_updates 1378 | best_bleu 37.51
2021-02-02 16:42:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:42:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_last.pt (epoch 9 @ 1378 updates, score 36.13) (writing took 8.674427902325988 seconds)
2021-02-02 16:42:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-02-02 16:42:34 | INFO | train | epoch 009 | loss 2.289 | nll_loss 0.436 | ppl 1.35 | wps 13028.2 | ups 3.7 | wpb 3520.5 | bsz 610.3 | num_updates 1378 | lr 0.00017225 | gnorm 1.212 | loss_scale 0 | train_wall 29 | wall 464
2021-02-02 16:42:34 | INFO | fairseq_cli.train | begin training epoch 9
2021-02-02 16:42:38 | INFO | train_inner | epoch 010:     22 / 154 loss=2.284, nll_loss=0.432, ppl=1.35, wps=11056, ups=3.2, wpb=3450.7, bsz=585.2, num_updates=1400, lr=0.000175, gnorm=1.169, loss_scale=0, train_wall=18, wall=468
2021-02-02 16:42:57 | INFO | train_inner | epoch 010:    122 / 154 loss=2.271, nll_loss=0.418, ppl=1.34, wps=18857.3, ups=5.28, wpb=3571.8, bsz=641.3, num_updates=1500, lr=0.0001875, gnorm=1.004, loss_scale=0, train_wall=19, wall=487
2021-02-02 16:43:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-02-02 16:43:04 | INFO | fairseq.tasks.translation | example hypothesis: Götz select the category from the list. You can select as many categories as you like.
2021-02-02 16:43:04 | INFO | fairseq.tasks.translation | example reference: Select the category from the list. You can select as many or as few categories as you like.
2021-02-02 16:43:05 | INFO | fairseq.tasks.translation | example hypothesis: Götz downloads all messages to your local system, but other connections most often only download the headers, and get started reading the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:43:05 | INFO | fairseq.tasks.translation | example reference: POP mail downloads all messages to your local system, but other connections usually download just the headers, and get the rest only when you want to read the message. Before you go offline, Evolution downloads the unread messages from the folders you have chosen to store.
2021-02-02 16:43:06 | INFO | fairseq.tasks.translation | example hypothesis: Götz If the message uses the same header more than once, Evolution evaluates its first occurrence, even if the message redefines the header as UNKNOWNTOKENINHYP example.com UNKNOWNTOKENINHYP the second time, Evolution filters as if the second value did not exist. Use regular expressions to filter messages that define the same headers more than once.
2021-02-02 16:43:06 | INFO | fairseq.tasks.translation | example reference: If a message uses a header more than once, Evolution pays attention only to the first instance, even if the message defines the header differently the second time. For example, if a message declares the Resent-From: header as UNKNOWNTOKENINREF engineering @ example.com UNKNOWNTOKENINREF and then restates it as UNKNOWNTOKENINREF marketing @ example.com UNKNOWNTOKENINREF, Evolution filters as though the second declaration did not occur. To filter on messages that use headers multiple times, use a regular expression.
2021-02-02 16:43:06 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.238 | nll_loss 2.587 | ppl 6.01 | bleu 35.45 | wps 1161.9 | wpb 1401.3 | bsz 50.3 | num_updates 1532 | best_bleu 37.51
2021-02-02 16:43:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-02-02 16:43:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints/GNOME_p_9_r/checkpoint_last.pt (epoch 10 @ 1532 updates, score 35.45) (writing took 9.762091042473912 seconds)
2021-02-02 16:43:16 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-02-02 16:43:16 | INFO | train | epoch 010 | loss 2.267 | nll_loss 0.413 | ppl 1.33 | wps 12851.6 | ups 3.65 | wpb 3520.5 | bsz 610.3 | num_updates 1532 | lr 0.0001915 | gnorm 1.033 | loss_scale 0 | train_wall 29 | wall 506
2021-02-02 16:43:16 | INFO | fairseq_cli.train | done training in 496.3 seconds


###############################################################################
Peregrine Cluster
Job 17792409 for user 's3475743'
Finished at: Tue Feb  2 16:43:20 CET 2021

Job details:
============

Job ID              : 17792409
Name                : GNOME_p9_r
User                : s3475743
Partition           : gpu
Nodes               : pg-gpu15
Number of Nodes     : 1
Cores               : 12
State               : COMPLETED
Submit              : 2021-02-02T15:09:00
Start               : 2021-02-02T16:34:29
End                 : 2021-02-02T16:43:20
Reserved walltime   : 23:55:00
Used walltime       : 00:08:51
Used CPU time       : 00:09:05 (efficiency:  8.56%)
% User (Computation): 60.74%
% System (I/O)      : 39.26%
Mem reserved        : 32G/node
Max Mem used        : 5.61G (pg-gpu15)
Max Disk Write      : 51.20K (pg-gpu15)
Max Disk Read       : 2.22M (pg-gpu15)
Average GPU usage   : 25.8% (pg-gpu15)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/introduction/scientific_output

################################################################################
